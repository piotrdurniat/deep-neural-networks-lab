{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab11.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MsITBHLCFCnJ"},"source":["# Wstęp\n","Zadanie 12 jest trzecią częścią do zajęć laboratoryjnych poświęconych sieciom rekurencyjnym i predykcji z wykorzystaniem danych multimodalnych. Efektem prac będzie sieć rekurencyjna do predykcji kursu kryptowaluty Bitcoin (BTC) w oparciu o dane z giełdy oraz o wyniki analizy emocji komunikatów z mediów społecznościowych, do których również należy utworzyć dedykowany model sieci rekurencyjnej. Plan realizacji etapów wygląda następująco:\n","\n","1.   EmoTweet - model sieci rekurencyjnej do analizy emocji (10 pkt., laboratorium 10)\n","2. Agregacja informacji emotywnej i przygotowanie MultiBTC - multimodalnego model sieci rekurencyjnej do predykcji kursu BTC (10 pkt., laboratorium 11)\n","3. Ewaluacja modelu MultiBTC (10 pkt., laboratorium 12)\n","\n","Łącznie można otrzymać 30 punktów.\n","\n","# Cel ćwiczenia\n","\n","Celem trzeciego etapu prac jest ewaluacja modelu MultiBTC sieci rekurencyjnej LSTM do przewidywania kolejnego elementu sekwencji pod warunkiem wcześniejszych obserwacji. \n","\n","# Warunki zaliczenia\n","\n","Do zaliczenia trzeciego etapu należy wytrenować modelu oraz wykonać ewaluację predykcji dla scenariusza godzinnego oraz dziennego, z uwzględnieniem wpływu:\n"," * wybranych hiperparametrów \n"," * dodatkowych kroków wstępnego przetwarzania danych\n"," * wymiarów afektywnych\n"]},{"cell_type":"markdown","metadata":{"id":"YF_IigDfLjl-"},"source":["# Realizacja zadania\n","\n","Szczegółowa realizacja zadania powinna uwzględniać następujące elementy ewaluacji:\n","\n","### Hiperparametry (4 pkt.)\n","\n","W zadaniu tym istnieje szereg ustawień hiperparametrów, które mogą mieć istotny wpływ na jakość predykcji. Należy wybrać jeden z nich i zbadać jego wpływ dla 3 wybranych wartości. \n","\n","1. Długość sekwencji w modelu LSTM.\n","2. Liczba jednostek w warstwie ukrytej. \n","3. Optymalizator i jego parametry (np. `learning rate`).\n","4. Użycie dodatkowej warstwy Dropout (parametr: `probability`) przed warstwą z wynikiem predykcji.\n","\n","### Przetwarzanie wstępne (3 pkt.)\n","\n","Jednocześnie istotny wpływ mogą mieć dodatkowe elementy przetwarzania wstępnego danych. Należy wybrać jeden z nich i porównać z wariantem bez przetwarzania:\n","1. Normalizacja wartości (sprowadzenie konkretnych kwot do wartości z zakresu 0-1).\n","2. Zamiana wartości liczbowej na procentową zmianę względem poprzedniego kursu.\n","\n","### Wymiary afektywne  (3 pkt.)\n","\n","Ostatnim aspektem jest zbadanie wpływu wymiarów afektywnych. Dla najlepszej otrzymanej konfiguracji należy porównać wyniki z modelem, który wykorzystuje wyłącznie dane z giełdy.\n","\n","### Ogólne uwagi końcowe\n","\n","Wszystkie wyniki proszę podać z wykorzystaniem 2 miar jakości predykcji:\n","1. [Mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error)\n","2. [R2-score](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n","\n","Przy każdej procedurze uczenia należy wykorzystywać zbiór walidacyjny w taki sposób, by po każdej epoce uczenia sprawdzać jakość predykcji na tym zbiorze. Należy zapamiętać ten model, którego jakość była najlepsza na zbiorze walidacyjnym i na tym modelu dopiero robić ostateczną ewaluację z wykorzystaniem zbioru testowego. Proszę obserwować proces uczenia. Spadek jakości na zbiorze walidacyjnym w dalszych epokach uczenia (po wcześniejszym wzrastaniu w poprzednich epokach) może oznaczać, że model przeuczył się na zbiorze uczącym i można przerwać trenowanie. Często definiuje się w tym celu dodatkowy parametr tzw. **cierpliwości** (ang. patience), który określa, przez ile epok możemy kontynuować uczenie bez otrzymania wyniki lepszego niż dotychczasowy najlepszy.\n"]}]}