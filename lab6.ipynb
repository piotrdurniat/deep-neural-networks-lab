{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7ohrpn4zljk"
      },
      "source": [
        "# Wstęp\n",
        "Zadanie 6 stanowi wprowadzenie w tematykę *data augmentation*. Ze względu na złożonośc modeli głębokich, zwykle wymagają one bardzo dużych zbiorów danych do dobrego wyuczenia. Jednym ze sposobów na skalowanie ilości dostępnych danych są metody tzw. augmentacji - przekształcenia na danych które mamy, aby utworzyć nowe przykłady o znanych etykietach. Pod koniec zadania wprowadzona jest również koncepcja *skip connections*, będących istotnym elementem współczesnych architektur konwolucyjnych i nie tylko."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db2J8maDszza"
      },
      "source": [
        "#Cel ćwiczenia\n",
        "\n",
        "Celem ćwiczenia jest zapoznanie się z\n",
        "\n",
        "*    koncepcją augmentacji danych\n",
        "*    implementacją metod augmentacji danych obrazowych w torch.transforms\n",
        "*    koncepcją augmentacji niezależnej od dziedziny\n",
        "*    modelami sieci głębokich ze skip connections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4fhynJbFsoj"
      },
      "source": [
        "#Augmentacja danych obrazowych\n",
        "\n",
        "W pierwszej kolejności zapoznajmy się z funkcjonalnością augmentacji danych obrazowych. W pytorch funkcjonalność ta realizowana jest przez transformacje wykonywane na obrazach przez `torchvision.transforms`.\n",
        "\n",
        "Transformacje które typowo wykorzystuje się w augmentacji to standardowe przekształcenia afiniczne obrazu - rotacje, dobicia, skalowanie. Oczywiście, pownniśmy dobierać transformacje z takich, po których rzeczywiście oczekujemy inwariancji - przekształcony obraz będziemy podawać do sieci z tą samą etykietą. Przykładowo, na zbiorze odręcznie pisanych cyfr MNIST ograniczymy zakres obrotów czy wykorzystanie odbicia w osi poziomej, jako że niechcemy pomylić 5 z 2 czy 6 z 9.\n",
        "\n",
        "Zapoznaj się z dokumentacją transforms tutaj:\n",
        "\n",
        "https://pytorch.org/vision/stable/transforms.html\n",
        "\n",
        "Kod poniżej wczytuje CIFAR 10 i pokazuje wyniki przykładowej augmentacji - losowej rotacji o kąt -30 do 30 stopni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "jVsqOyfLyf66",
        "outputId": "e616ad3e-8506-4169-a154-72cee464b96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to cifar_root/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 48235238.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting cifar_root/cifar-10-python.tar.gz to cifar_root\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.RandomRotation(30), transforms.ToTensor()])\n",
        "\n",
        "train_ds = torchvision.datasets.CIFAR10(\n",
        "    \"cifar_root\", transform=transform, download=True\n",
        ")\n",
        "img, label = train_ds[0]\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()\n",
        "\n",
        "img, label = train_ds[0]\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PhVqir8Ewhc"
      },
      "source": [
        "Widzimy tutaj kolejny potencjalny problem z augmentacjami: ze względu na konieczność utrzymania stałego kształtu wejścia, augmentacje mogą wprowadzać artefakty takie jak czarne fragmenty na krawędziach obrazu czy aliasing wynikający z niskiej rozdzielczości.\n",
        "\n",
        "Poniżej kod pomocniczy z laboratorium 3, można zastąpić go własną implementacją pętli uczącej uwzględniającej ulepszenia wykonane na laboratoriach 4 i 5. W zadaniach poniżej wystarczy porównać końcowy wynik uczenia, nie jest wymagane wyrysowywanie pełnych krzywych w tensorboard niemniej mogą one pomóc w analizie otrzymanych wyników."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJF5ojwhhIKI",
        "outputId": "ebee5a2c-65b2-4084-f396-3248a3eae995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Tuple\n",
        "from tqdm import tqdm\n",
        "\n",
        "transform = torchvision.transforms.ToTensor()\n",
        "\n",
        "train_ds = torchvision.datasets.CIFAR10(\n",
        "    \"cifar_root\", transform=transform, download=True\n",
        ")\n",
        "test_ds = torchvision.datasets.CIFAR10(\n",
        "    \"cifar_root\", transform=transform, train=False, download=True\n",
        ")\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=32, pin_memory=True)\n",
        "\n",
        "\n",
        "def count_correct(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
        "    preds = torch.argmax(y_pred, dim=1)\n",
        "    return (preds == y_true).float().sum()\n",
        "\n",
        "\n",
        "def validate(\n",
        "    model: nn.Module, loss_fn: torch.nn.CrossEntropyLoss, dataloader: DataLoader\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    all = 0\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        y_pred = model(X_batch.cuda())\n",
        "        all += len(y_pred)\n",
        "        loss += loss_fn(y_pred, y_batch.cuda()).sum()\n",
        "        correct += count_correct(y_pred, y_batch.cuda())\n",
        "    return loss / all, correct / all\n",
        "\n",
        "\n",
        "def fit(\n",
        "    model: nn.Module,\n",
        "    optimiser: optim.Optimizer,\n",
        "    loss_fn: torch.nn.CrossEntropyLoss,\n",
        "    train_dl: DataLoader,\n",
        "    val_dl: DataLoader,\n",
        "    epochs: int,\n",
        "    print_metrics: bool = True,\n",
        "):\n",
        "    for epoch in range(epochs):\n",
        "        for X_batch, y_batch in tqdm(train_dl):\n",
        "            y_pred = model(X_batch.cuda())\n",
        "            loss = loss_fn(y_pred, y_batch.cuda())\n",
        "\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "            optimiser.zero_grad()\n",
        "\n",
        "        if print_metrics:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                train_loss, train_acc = validate(\n",
        "                    model=model, loss_fn=loss_fn, dataloader=train_dl\n",
        "                )\n",
        "                val_loss, val_acc = validate(\n",
        "                    model=model, loss_fn=loss_fn, dataloader=val_dl\n",
        "                )\n",
        "                print(\n",
        "                    f\"Epoch {epoch}: \"\n",
        "                    f\"train loss = {train_loss:.3f} (acc: {train_acc:.3f}), \"\n",
        "                    f\"validation loss = {val_loss:.3f} (acc: {val_acc:.3f})\"\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z79oc3U1vK5x"
      },
      "source": [
        "# Zadanie 1\n",
        "\n",
        "Wykorzystując klasę ThreeLayerCNN, spróbuj dobrać augmentacje danych tak aby poprawić wyniki względem jej braku na zbiorze CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sGaP3-h8gfq4"
      },
      "outputs": [],
      "source": [
        "class ThreeLayerCNN(torch.nn.Module):\n",
        "    def __init__(self, channels: int, labels: int):\n",
        "        super().__init__()\n",
        "        self.model = torch.nn.Sequential()\n",
        "        self.model.add_module(\"conv_1\", torch.nn.Conv2d(3, channels, 3, padding=1))\n",
        "        self.model.add_module(\"relu_1\", torch.nn.ReLU())\n",
        "        self.model.add_module(\"max_pool_1\", torch.nn.MaxPool2d(2))\n",
        "        self.model.add_module(\n",
        "            \"conv_2\", torch.nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        )\n",
        "        self.model.add_module(\"relu_2\", torch.nn.ReLU())\n",
        "        self.model.add_module(\"max_pool_2\", torch.nn.MaxPool2d(2))\n",
        "        self.model.add_module(\n",
        "            \"conv3\", torch.nn.Conv2d(channels, channels, 3, padding=1)\n",
        "        )\n",
        "        self.model.add_module(\"flatten\", torch.nn.Flatten())\n",
        "        self.model.add_module(\"linear\", torch.nn.Linear(8 * 8 * channels, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmcSjippSl5S"
      },
      "source": [
        "Zaprogramuj eksperyment tak, aby w pętli sprawdzać kolejne potencjalne wersje potoku przetwarzania (różniące się tutaj tylko augmentacją), a na końcu wybrać najlepszą - tak aby możliwe było powtórzenie całego eksperymentu uzasadniającego wybór! Transformacja z augmentacją ma być wywoływana tylko na danych treningowych.\n",
        "\n",
        "Spróbuj znaleźć również przykład augmentacji pogarszającej wynik w stosunku do bazowego otrzymanego bez augmentacji. Wykorzystaj uczenie na 50 epok i optymalizator Adam z domyślnymi parametrami, bez regularyzacji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX1kfmRGW_z1",
        "outputId": "16a901e7-8299-417c-e819-0bb63bf17f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Augmentation type: RandomRotation(degrees=[-10.0, 10.0], interpolation=InterpolationMode.NEAREST, expand=False, fill=0)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:51<00:00, 30.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.042 (acc: 0.514), validation loss = 0.043 (acc: 0.509)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:47<00:00, 32.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.035 (acc: 0.613), validation loss = 0.036 (acc: 0.601)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:48<00:00, 31.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.031 (acc: 0.645), validation loss = 0.033 (acc: 0.629)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:48<00:00, 32.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.031 (acc: 0.650), validation loss = 0.033 (acc: 0.633)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:48<00:00, 32.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.031 (acc: 0.653), validation loss = 0.032 (acc: 0.638)\n",
            "\n",
            "Augmentation type: ColorJitter()\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:25<00:00, 60.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.039 (acc: 0.557), validation loss = 0.040 (acc: 0.545)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:25<00:00, 60.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.034 (acc: 0.623), validation loss = 0.035 (acc: 0.611)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:25<00:00, 60.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.031 (acc: 0.660), validation loss = 0.032 (acc: 0.647)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:25<00:00, 60.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.030 (acc: 0.669), validation loss = 0.032 (acc: 0.648)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:25<00:00, 62.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.028 (acc: 0.689), validation loss = 0.031 (acc: 0.662)\n",
            "\n",
            "Augmentation type: RandomHorizontalFlip(p=0.5)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 75.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.038 (acc: 0.575), validation loss = 0.038 (acc: 0.572)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:21<00:00, 71.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.033 (acc: 0.624), validation loss = 0.034 (acc: 0.611)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:21<00:00, 71.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.030 (acc: 0.667), validation loss = 0.031 (acc: 0.654)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:22<00:00, 68.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.028 (acc: 0.689), validation loss = 0.029 (acc: 0.666)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:21<00:00, 73.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.028 (acc: 0.690), validation loss = 0.030 (acc: 0.673)\n",
            "\n",
            "Augmentation type: RandomVerticalFlip(p=0.5)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 75.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.044 (acc: 0.491), validation loss = 0.044 (acc: 0.482)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 76.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.039 (acc: 0.546), validation loss = 0.040 (acc: 0.538)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 74.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.037 (acc: 0.572), validation loss = 0.038 (acc: 0.557)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 75.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.035 (acc: 0.598), validation loss = 0.036 (acc: 0.590)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:21<00:00, 73.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.034 (acc: 0.613), validation loss = 0.036 (acc: 0.594)\n",
            "\n",
            "Augmentation type: RandomGrayscale(p=0.1)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:21<00:00, 72.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.040 (acc: 0.553), validation loss = 0.040 (acc: 0.545)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:21<00:00, 72.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.036 (acc: 0.590), validation loss = 0.037 (acc: 0.580)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 76.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.032 (acc: 0.636), validation loss = 0.034 (acc: 0.615)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 75.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.030 (acc: 0.666), validation loss = 0.032 (acc: 0.643)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 77.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.028 (acc: 0.691), validation loss = 0.031 (acc: 0.662)\n"
          ]
        }
      ],
      "source": [
        "# zaprojektuj eksperyment sprawdzający kilka możliwych podejść do augmentacji, wybranych z dokumentacji torchvision.transforms\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transforms = [\n",
        "    v2.RandomRotation(10.0),\n",
        "    v2.ColorJitter(),\n",
        "    v2.RandomHorizontalFlip(),\n",
        "    v2.RandomVerticalFlip(),\n",
        "    v2.RandomGrayscale(p=0.1),\n",
        "]\n",
        "\n",
        "for augmentation in transforms:\n",
        "    print(f\"\\nAugmentation type: {augmentation}\")\n",
        "\n",
        "    transform = v2.Compose(\n",
        "        [v2.ToImage(), v2.ToDtype(torch.float32, scale=True), augmentation]\n",
        "    )\n",
        "\n",
        "    model = ThreeLayerCNN(32, 10)\n",
        "\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Datasets\n",
        "    train_ds = torchvision.datasets.CIFAR10(\n",
        "        \"cifar_root\", transform=transform, download=True\n",
        "    )\n",
        "    test_ds = torchvision.datasets.CIFAR10(\n",
        "        \"cifar_root\", transform=transform, train=False, download=True\n",
        "    )\n",
        "    train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, pin_memory=True)\n",
        "    test_dl = DataLoader(test_ds, batch_size=32, pin_memory=True)\n",
        "\n",
        "    fit(model, optimizer, loss_fn, train_dl, test_dl, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRMDOzslUAKW"
      },
      "source": [
        "# Mixup - augmentacja ogólna\n",
        "\n",
        "Augmentacja daje nam spore możliwości w sytuacji, gdy w dziedzinie danych jesteśmy w stanie wskazać przekształcenia na kóre nasz model powinien być **inwariantny** - dla obrazków niewielkie skalowanie czy przesunięcie nie powinno zmieniać wyniku, zaś dla tekstu, podstawianie synonimów może spełniać podobną rolę. Ale w augmentacji danych możliwe jest też podejście niezależne od typu danych, wynikające z obserwacji dotyczących dynamiki uczenia sieci głębokich w ogóle. Ciekawym przykładem jest tu augmentacja Mixup:\n",
        "\n",
        "https://arxiv.org/abs/1710.09412\n",
        "\n",
        "Zasada działania mixup jest niezwykle prosta - generujemy nowe przykłady jako **kombinacje liniowe** tych istniejących w zbiorze danych i oczekujemy, że ich etykiety również będą kombinacjami liniowymi etykiet. Innymi słowy, dla pary przykładów z etykietami: $(x_1, y_1)$, $(x_2, y_2)$, możemy wygenerować przykład $(x', y')$:\n",
        "\n",
        "$x' = \\lambda x_1 + (1-\\lambda) x_2$\n",
        "\n",
        "$y' = \\lambda y_1 + (1-\\lambda) y_2$\n",
        "\n",
        "Wartość $\\lambda$ jest tutaj losowana z rozkładu Beta - animacja podana na https://en.wikipedia.org/wiki/Beta_distribution#Definitions dobrze obrazuje, jak wygląda ten rozkład dla różnych parametryzacji."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRnbe1V6YfOY"
      },
      "source": [
        "# Zadanie 2\n",
        "\n",
        "Zmodyfikuj funkcję fit tak, aby uczyć zgodnie z podanym wyżej sformułowaniem augmentacji Mixup. Uwaga: będzie to wymagało modyfikacji funkcji kosztu!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FBCXRaAsT_Xe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    \"\"\"Returns mixed inputs, pairs of targets, and lambda\"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    \"\"\"Compute the mixup loss.\"\"\"\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "\n",
        "def fit_mix(model, optimizer, loss_fn, train_dl, val_dl, epochs, print_metrics=True):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in tqdm(train_dl):\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            X_mix, y_a, y_b, lam = mixup_data(X_batch, y_batch, alpha=0.2)\n",
        "\n",
        "            outputs = model(X_mix)\n",
        "\n",
        "            loss = mixup_criterion(loss_fn, outputs, y_a, y_b, lam)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if print_metrics:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                train_loss, train_acc = validate(\n",
        "                    model=model, loss_fn=loss_fn, dataloader=train_dl\n",
        "                )\n",
        "                val_loss, val_acc = validate(\n",
        "                    model=model, loss_fn=loss_fn, dataloader=val_dl\n",
        "                )\n",
        "                print(\n",
        "                    f\"Epoch {epoch}: \"\n",
        "                    f\"train loss = {train_loss:.3f} (acc: {train_acc:.3f}), \"\n",
        "                    f\"validation loss = {val_loss:.3f} (acc: {val_acc:.3f})\"\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bId62ojPhzkU"
      },
      "source": [
        "Sprawdź, czy uzyskuje ona przewagę nad modelem trenowanym bez augmentacji.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "727vLU-8h6EE",
        "outputId": "9f7e2453-e303-4875-97ff-87a200877b5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:10<00:00, 143.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.037 (acc: 0.576), validation loss = 0.038 (acc: 0.565)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:10<00:00, 147.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.033 (acc: 0.633), validation loss = 0.035 (acc: 0.611)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:11<00:00, 138.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.030 (acc: 0.672), validation loss = 0.032 (acc: 0.646)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:10<00:00, 142.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.027 (acc: 0.699), validation loss = 0.030 (acc: 0.668)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:11<00:00, 136.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.026 (acc: 0.722), validation loss = 0.029 (acc: 0.688)\n",
            "Validation accuracy without augmentation: tensor(0.6875, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# przetestuj wyniki z wykorzystaniem zmodyfikowanego fit()# Train the model without augmentation\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=32, pin_memory=True)\n",
        "\n",
        "model_no_aug = ThreeLayerCNN(channels=32, labels=10)\n",
        "model_no_aug.to(device)\n",
        "optimizer_no_aug = optim.Adam(model_no_aug.parameters())\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "fit(model_no_aug, optimizer_no_aug, loss_fn, train_dl, test_dl, epochs=5)\n",
        "\n",
        "model_no_aug.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, acc_no_aug = validate(model_no_aug, loss_fn, test_dl)\n",
        "\n",
        "\n",
        "print(\"Validation accuracy without augmentation:\", acc_no_aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe7dZorbfmSE",
        "outputId": "72f9aa10-bb4a-4e80-df32-3a2a921e2c87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:10<00:00, 143.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.039 (acc: 0.569), validation loss = 0.039 (acc: 0.565)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:11<00:00, 137.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.036 (acc: 0.603), validation loss = 0.037 (acc: 0.588)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 126.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.031 (acc: 0.667), validation loss = 0.033 (acc: 0.647)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 123.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.029 (acc: 0.680), validation loss = 0.031 (acc: 0.659)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:14<00:00, 104.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.028 (acc: 0.698), validation loss = 0.031 (acc: 0.675)\n",
            "Validation accuracy with Mixup augmentation: tensor(0.6746, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train the model with Mixup augmentation\n",
        "model_mixup = ThreeLayerCNN(channels=32, labels=10)\n",
        "model_mixup.to(device)\n",
        "optimizer_mixup = optim.Adam(model_mixup.parameters())\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "fit_mix(model_mixup, optimizer_mixup, loss_fn, train_dl, test_dl, epochs=5)\n",
        "\n",
        "model_mixup.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, acc_mixup = validate(model_mixup, loss_fn, test_dl)\n",
        "\n",
        "print(\"Validation accuracy with Mixup augmentation:\", acc_mixup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3QMNaOb9lvp"
      },
      "source": [
        "# Skrótowe połączenia\n",
        "\n",
        "W kontekście sieci konwolucyjnych warto zpoznać się jeszcze z jedną istotną koncepcją: połączenia omijające warstwy, poprzez konkatenacje ich wyniku z wynikami dalszych warstw lub dodawanie ich wyniku do wyjścia dalszej warstwy (w drugim przypadku mówimy też o połączeniach *rezydualnych*). Połączenia takie są potrzebne szczególnie przy trenowaniu sieci bardzo głębokich, zawierających dziesiątki czy nawet ponad 100 warstw, czego nie będziemy w stanie realistycznie zrealizować w czasie naszych laboratoriów. Niemniej warto zapoznać się zarówno z samą ideą, jak i ich implementacją, jako że przy pracy z architekturami *state of the art* będziemy często natykać się na takie konstrukcje.\n",
        "\n",
        "W konstrukcji sieci z połączeniamy pomijającymi warstwy i połączeniami rezydualnymi często będziemy spotykać się z powtarzalnymi *blokami* obejmującymi kilka warstw - dobrą praktyką implementacyjną jest wydzielanie takich bloków jako osobnych podklas `torch.nn.Module`. Warto też z góry zwrócić uwagę, że znane nam już `torch.nn.Sequential` nie uwzględnia połączeń innych niż sekwencyjne - czyli połączenia rezydualne i omijanie warstw nie wchodzi w grę, chyba że w obrębie wydzielonego bloku."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxUiBYYX_lcb"
      },
      "source": [
        "# Zadanie 3\n",
        "\n",
        "Uzupełnij kod klasy SkipBlock tak, aby implementowała blok o zadanej strukturze.\n",
        "\n",
        "Struktura SkipBlock:\n",
        "\n",
        "główna sekwencja warstw\n",
        "\n",
        "*   warstwa konwolucyjna, nie zmieniająca wymiarów szerokość/wysokość, `in_channels x out_channels`, filtr 3x3\n",
        "*   aktywacja ReLU\n",
        "*   warstwa konwolucyjna, wykonująca downsampling x2 w wymiarach szerokość/wysokość, filtr 3x3\n",
        "\n",
        "warstwa poboczna (na wejściu: wejście do całego bloku, wyjście dodawane jest do wyjścia sekwencji powyżej)\n",
        "\n",
        "*    warstwa konwolucyjna, filtr 2x2\n",
        "\n",
        "**Samodzielnie dobierz niesprecyzowane parametry** tak, aby wymiary odpowiednich wyjść się zgadzały. Wyjście bloku powinno mieć `out_channels` kanałów oraz dwukrotnie zmniejszoną wysokość i szerokość w stosunku do wejścia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cVJ1cGOs9lSg"
      },
      "outputs": [],
      "source": [
        "class SkipBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super(SkipBlock, self).__init__()\n",
        "        self.main_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=2),\n",
        "        )\n",
        "        self.side_conv = nn.Conv2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        main_out = self.main_conv(x)\n",
        "        side_out = self.side_conv(x)\n",
        "        return main_out + side_out\n",
        "\n",
        "\n",
        "class SkipBlockCNN(torch.nn.Module):\n",
        "    def __init__(self, channels: list[int], labels: int):\n",
        "        super().__init__()\n",
        "        self.model = torch.nn.Sequential()\n",
        "        self.model.add_module(\"res_1\", SkipBlock(3, channels[0]))\n",
        "        self.model.add_module(\"relu_1\", torch.nn.ReLU())\n",
        "        self.model.add_module(\"res_2\", SkipBlock(channels[0], channels[1]))\n",
        "        self.model.add_module(\"relu_2\", torch.nn.ReLU())\n",
        "        self.model.add_module(\"res_3\", SkipBlock(channels[1], channels[2]))\n",
        "        self.model.add_module(\"relu_3\", torch.nn.ReLU())\n",
        "        self.model.add_module(\"flatten\", torch.nn.Flatten())\n",
        "        self.model.add_module(\"linear\", torch.nn.Linear(4 * 4 * channels[2], labels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMZNBCOmmu8I"
      },
      "source": [
        " Wyucz sieć SkipBlockCNN i porównaj jej wyniki z wcześniej uzykanymi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6r2bdnAmzob",
        "outputId": "2dd148d7-2d12-4597-f4a7-e8f2970747fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:14<00:00, 110.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss = 0.040 (acc: 0.545), validation loss = 0.041 (acc: 0.539)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:14<00:00, 108.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train loss = 0.034 (acc: 0.622), validation loss = 0.036 (acc: 0.598)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 123.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: train loss = 0.029 (acc: 0.677), validation loss = 0.033 (acc: 0.625)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 122.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: train loss = 0.025 (acc: 0.713), validation loss = 0.031 (acc: 0.649)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:12<00:00, 121.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: train loss = 0.022 (acc: 0.752), validation loss = 0.029 (acc: 0.673)\n",
            "Validation accuracy with Mixup augmentation: tensor(0.6727, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_skip_block = SkipBlockCNN([16, 32, 64], labels=10)\n",
        "\n",
        "model_skip_block.to(device)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=32, pin_memory=True)\n",
        "\n",
        "optimizer = optim.Adam(model_skip_block.parameters())\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "fit(model_skip_block, optimizer, loss_fn, train_dl, test_dl, epochs=5)\n",
        "\n",
        "model_skip_block.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, acc_skip_block = validate(model_skip_block, loss_fn, test_dl)\n",
        "\n",
        "print(\"Validation accuracy with skip block:\", acc_skip_block)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
